# ğŸŒ Projet de Load Balancing avec HAProxy et Node.js

## ğŸ“– Objectif

Ce projet a pour but de dÃ©montrer les principes fondamentaux de lâ€™Ã©quilibrage de charge (load balancing) Ã  lâ€™aide de HAProxy sur un environnement conteneurisÃ© Docker.

Lâ€™objectif est de rÃ©partir les requÃªtes HTTP entrantes entre deux serveurs Node.js distincts afin dâ€™assurer :
- une meilleure disponibilitÃ©,
- une distribution Ã©quilibrÃ©e du trafic,
- et une meilleure tolÃ©rance aux pannes.

## âš™ï¸ Architecture du projet

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ haproxy.cfg
â”œâ”€â”€ Makefile
â”œâ”€â”€ nodeServer1.js
â””â”€â”€ nodeServer2.js
```

### ğŸ”§ Composants
- 2 serveurs Node.js (`nodeServer1.js` et `nodeServer2.js`) :  
  â†’ RÃ©pondent chacun sur un port diffÃ©rent (3000 et 3001).  
- HAProxy :  
  â†’ Fait office dâ€™Ã©quilibreur de charge en rÃ©partissant les requÃªtes HTTP entre les deux serveurs.  
- Docker Compose :  
  â†’ Orchestre le lancement de tous les conteneurs.  

## ğŸ§± Structure Docker

### ğŸ”¹ Fichier `Dockerfile`
Ce fichier dÃ©crit comment construire lâ€™image Node.js utilisÃ©e pour les serveurs :
```Dockerfile
FROM node:22-alpine
WORKDIR /app
COPY . .
CMD ["node", "server1.js"]
```

Chaque conteneur Node exÃ©cute une instance du serveur sur un port diffÃ©rent.


## ğŸŒ Fichier `haproxy.cfg`

```cfg
frontend http-in
    bind *:8080
    default_backend nodes

backend nodes
    balance roundrobin
    option httpchk GET /
    server s1 node1:3000 check
    server s2 node2:3001 check

listen stats
    bind *:8404
    stats enable
    stats uri /
    stats refresh 1s
    stats auth admin:admin
```

HAProxy Ã©coute sur le port `8080` et rÃ©partit le trafic entre les serveurs Node (3000 et 3001).  
La page dâ€™administration est disponible sur le port `8404`.

## ğŸ§® Test de fonctionnement

### AccÃ©der Ã  lâ€™application :
[http://localhost:8080](http://localhost:8080)

En rechargeant plusieurs fois la page, nous verrons alterner :
```
Connexion to server 1
Connexion to server 2
```

Une autre maniÃ¨re de voir les connexions est de gÃ©nerer des connexions. Il est possible de le faire avec cette commande dans le terminal.

#### PowerShell :
```powershell
for ($i=1; $i -le 100; $i++) {
    $resp = Invoke-WebRequest http://localhost:8080
    Write-Host "$i -> $($resp.Content.Trim())"
}
```

#### Linux :
```bash
for i in {1..100}; do echo -n "$i -> "; curl -s http://localhost:8080; done
```

### AccÃ©der Ã  la page dâ€™administration :
[http://localhost:8404](http://localhost:8404)  

```
username: admin
password: admin
```

Il est possible de voir :
- lâ€™Ã©tat des backends,
- le nombre de requÃªtes,
- les statistiques en temps rÃ©el.

## ğŸ“Š Surveillance HAProxy

Dans le tableau de bord HAProxy (port `8404`), nous pouvons :
- observer les requÃªtes en direct,
- vÃ©rifier lâ€™Ã©tat des serveurs,
- visualiser le dÃ©bit et le taux dâ€™erreur.


## ğŸ Conclusion

Ce projet illustre comment :
- configurer HAProxy comme load balancer,
- distribuer le trafic entre plusieurs serveurs Node.js,
- conteneuriser et orchestrer le tout avec Docker,
- surveiller et tester le comportement du systÃ¨me.
